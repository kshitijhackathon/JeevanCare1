
---

## Detailed Rationale & Implementation Guide

### 1. Speech-to-Text: Capturing Patient’s Spoken Symptoms
- **Why Whisper or Bhashini?**  
  • Whisper (OpenAI) offers high accuracy across multiple Indian accents, can run offline if you host it locally.  
  • Bhashini, under MeitY, is India’s national multilingual voice platform—free for government-approved use.  
- **Integration Tips:**  
  • Record user audio from the app/web mic.  
  • Send it to Whisper/Bhashini API endpoint.  
  • Receive raw transcript (UTF-8 text) in the patient’s native language.

### 2. IndicTrans: Translating to a Common LLM Language
- **Why IndicTrans?**  
  • Open-source, actively maintained by IITs.  
  • Covers Hindi, Bengali, Tamil, Telugu, Marathi, Gujarati, Malayalam, Kannada.  
- **Integration Tips:**  
  • Feed the raw transcript into IndicTrans.  
  • Receive a clean English translation.  
  • Store it in `patient.symptoms` for the next stage.

### 3. LLM Prompting: Doctor Simulation
- **Choice of Model:**  
  • **ChatGPT API (Free Tier):** reliable, robust, but rate-limits apply.  
  • **Open-Source LLMs:** LLaMA-3, Mistral, MedPaLM—can self-host with frameworks like **LangChain** for conversational memory and reagent chaining.
- **Prompt Engineering:**  
  • Use the **System Prompt** (above) verbatim with tool directives.  
  • Append the JSON `patient` object as the user message.  
  • Call the model with parameters tuned for clarity (e.g., temperature 0.2–0.5 for balanced creativity vs. determinism).
- **Error Handling:**  
  • If the model returns non-JSON, implement a retry or simple regex-based clean-up.  
  • Validate JSON schema strictly; if invalid, fallback to a safe “I’m sorry” message.

### 4. JSON Schema: Structured, Predictable Output
- **Why JSON?**  
  • Easy for your backend to parse.  
  • Guarantees fields for UI rendering (text, questions, tests, medicines).  
- **Field Details:**  
  – `responseText`: localized advice, ≤ 15 words/sentence.  
  – `followUp`: array of clarifying questions (strings), empty if none.  
  – `tests`: array of test names.  
  – `medicines`: list of objects—name, dose, freq, days.  
  – `severity`: “low”, “moderate”, or “high”.

### 5. Text-to-Speech: Converting Advice Back to Audio
- **gTTS for MVP:**  
  • Lightweight, simple Python lib.  
  • Supports major Indian language codes (hi, bn, ta, te, mr, en).  
  • Usage: `gTTS(text=responseText, lang=patient.lang).save("reply.mp3")`.
- **Future Upgrade – Coqui / Silero:**  
  • For more natural intonation, emotional prosody, and smoother audio.  
  • Requires GPU for real-time synthesis at scale.

---

## Integration Sketch (Replit / Node / Python Backend)

```python
# 1. Capture user audio (e.g., from WebSocket stream).
audio_data = receive_audio_stream()

# 2. STT via Whisper/Bhashini → raw_text
raw_text = speech_to_text_whisper(audio_data)
# or: raw_text = bhashini_recognize(audio_data)

# 3. Translate → English
eng_text = indictrans_translate(raw_text)

# 4. Build patient JSON
patient = {
    "name": user_name,
    "age": user_age,
    "gender": user_gender,
    "bloodGrp": user_blood_group,
    "symptoms": eng_text,
    "lang": user_language_code
}

# 5. Call LLM with system prompt + patient JSON
response = llm.call(
    system_prompt=SYSTEM_PROMPT,
    user_message=json.dumps(patient),
    temperature=0.3,
    max_tokens=400
)

# 6. Parse JSON from response
advice = json.loads(response)

# 7. (Optional) If advice['responseText'] is in English but lang != "en", translate back
localized_text = indictrans_back_translate(advice["responseText"], target_lang=patient["lang"])

# 8. Convert to speech
tts = gTTS(text=localized_text, lang=patient["lang"])
tts.save("reply.mp3")

# 9. Stream reply.mp3 back to user
stream_audio("reply.mp3")
