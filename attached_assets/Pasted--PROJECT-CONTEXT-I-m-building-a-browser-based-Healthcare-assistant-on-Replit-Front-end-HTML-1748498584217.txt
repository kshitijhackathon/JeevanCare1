ğŸ””  PROJECT CONTEXT
Iâ€™m building a browser-based Healthcare assistant on Replit.  
Front-end: HTML + Tailwind CSS + JavaScript  
Back-end: pure browser JS calling an LLM endpoint (currently Groq / Claude) for dialogue.  
Target language: Hinglish.  
Key feature:  the AI must read the userâ€™s free-text or voice-to-text messages, extract symptoms accurately, keep conversation context, recognise regional synonyms (â€œdardâ€, â€œtakleefâ€, â€œjalanâ€, â€œsujanâ€, etc.), and reply with precise, doctor-style Hinglish answersâ€”**never** generic â€œMain aapki baat samajh gayaâ€ lines.

At present we see four gaps:  
1 ï¸âƒ£ **Generic fallback answers.** Model sometimes replies â€œMain aapki baat samajh gayaâ€ without specific diagnostic follow-ups.  
2 ï¸âƒ£ **Complex condition miss.** It fails to connect multi-symptom inputs (e.g., â€œbukhaar + pet dard + loose motionsâ€) to likely diagnoses (gastroenteritis, appendicitis, etc.).  
3 ï¸âƒ£ **Regional synonym miss.** Different Hindi words for pain (â€œdardâ€, â€œpeedaâ€, â€œtakleefâ€) or burning (â€œjalanâ€, â€œsoojaâ€, â€œjalanâ€) are not mapped, so NLU fails.  
4 ï¸âƒ£ **No context memory.** Each new user line is treated in isolation; the model forgets previous complaints, medicines already suggested, or vitals collected.

âš ï¸  We must fix these WITHOUT leaving the browser sandbox (no server-side Python), but we can call remote APIs (Groq / Claude / OpenAI etc.) and can ship static files (JSON, JS modules) within Replit.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ¯  WHAT I NEED FROM YOU (REPLIT AI)

Design and generate the **code, data, and LLM-prompt strategy** that will close the four gaps above.  Deliver:

A.  **JavaScript module `symptomNLP.js`** that runs 100 % in the browser and exports:
    â€¢ `extractEntities(text, lang)`  â†’ returns array of {entity, type} where type âˆˆ {symptom, duration, severity, body_part}.  
    â€¢ `normalizeWord(word)` using a **synonym map** you will generate (see C).  
    â€¢ `mergeWithContext(entities, sessionCtx)` to produce an updated `sessionCtx` object.

B.  **Session-context store** (simple in-memory JS object) with helpers:
    â€¢ `getCtx()` / `setCtx()`  
    â€¢ `resetCtx()` when a new consultation starts.  
    This ensures the LLM prompt always contains last N user + assistant turns, vitals, allergies, tests already ordered, etc.

C.  **`symptom_synonyms.json`** containing at least **150 Hindi/Hinglish symptom synonyms** mapped to canonical English medical terms, e.g.  
```json
{ "dard": "pain", "takleef": "pain", "peeda": "pain",
  "bukhaar": "fever", "tap": "fever",
  "jalan": "burning", "jalaa": "burning",
  "sujan": "swelling", "soojan": "swelling",
  "ulTi": "vomiting", "ulti": "vomiting",
  ...
}
You can hard-code this as a JS object or import the JSON.

D. Improved LLM prompt template (doctorPrompt.js) that:

Injects the normalised symptom list and sessionCtx into the system-level prompt EACH TURN.

Includes a â€œmedical reasoning scaffoldâ€ instructing the model to:
â€¢ Acknowledge each recognised symptom with Hinglish restatement.
â€¢ Ask at least one follow-up question per unclarified symptom.
â€¢ Suggest likely diagnoses ranked by probability.
â€¢ Avoid generic replies; if unsure, ask clarifying questions.

States a hard rule: replies must be professional Hinglish; avoid pure fillers.

E. Test harness:
â€¢ HTML test page with a textarea for input and a pre tag for JSON debug output.
â€¢ Script runs extractEntities, updates context, then prints the outbound prompt so we can inspect what goes to the LLM.
â€¢ Provide 5 demo sentences illustrating edge cases (combo symptoms, synonym use, context reference).

F. Edge-case unit tests written with plain JS or Vitest (if available) proving:
â€¢ Same meaning phrase with different synonyms maps to same canonical entity.
â€¢ Previous-turn context is retained.
â€¢ Combined multi-symptom message yields >2 entities.
â€¢ No generic fallback appears in LLM response stub (you may mock with regex).

G. Comment blocks explaining how to plug your module into existing main.js where voice transcript arrives:

js
Copy
Edit
import { extractEntities, mergeWithContext } from "./symptomNLP.js";
const speechText = transcript.toLowerCase();
const ents = extractEntities(speechText, "hi-IN");
ctx = mergeWithContext(ents, ctx);
const prompt = buildPrompt(ctx, doctorPromptTemplate);
const response = await fetchLLM(prompt);
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸš€ ARCHITECTURE & IMPLEMENTATION DETAILS

Entity extraction approach (browser-only).
Use a two-step rule-based methodâ€”fast and no server:
â€¢ Tokenise input with a simple regex (/\w+/gu).
â€¢ For each token, normalizeWord(token) â†’ canonical term via symptom_synonyms.
â€¢ Collect multi-word patterns (e.g., â€œpet dardâ€, â€œseene mein jalanâ€) with small regex library; return entities with offsets for future UI highlighting.

Context modelling.
Represent context as:

js
Copy
Edit
ctx = {
  userInfo: { name, age, gender, allergies },
  symptoms: { "pain": {location:"abdomen", duration:"3 days"} , "fever": {...} },
  testsOrdered: [],
  lastAssistantTurn: "",
  lastUserTurn: ""
}
mergeWithContext updates/extends ctx.symptoms rather than overwriting, giving the LLM cumulative knowledge.

Prompt assembly.
Build a string roughly like:

yaml
Copy
Edit
System: Aap ek AI doctor ho jo Hinglish mein baat karta hai...
Known context: {ctx as JSON}
User said (latest): "<raw user text>"
Extracted entities: pain (abdomen, 3 days), fever (high)...
Rules: 1) Har symptom ko address karo. 2) Generic replies mana hai...
Model choice & temperature.
Maintain low temperature (0.2) to reduce hallucination.
Include a stop condition that if model tries to fall back to â€œMain samajh gayaâ€ without specifics, the front-end shows a â€œclarification requiredâ€ notice and automatically re-prompts user for details.

Regional language expansion.
Extend synonym map to include Urdu-influenced words (â€œsardardâ€, â€œkabzâ€), Marathi/Tamil borrowings if plausible. Add a quick-add helper so we can push new synonyms to symptom_synonyms.json without redeploying.

Performance note.
Keep symptomNLP.js < 25 KB gzipped; load once and cache.
Use Intl.Segmenter if available for better tokenisation on Hindi scripts; else fallback to regex.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”¬ DELIVERABLE FORMAT

Please output:

symptomNLP.js â€“ fully commented ES module

symptom_synonyms.json â€“ initial 150+ entries

doctorPrompt.js â€“ template string with placeholders and builder function

contextStore.js â€“ get/set/reset helpers

testHarness.html + testHarness.js â€“ demo/testing UI

README_FIX_VOICE.md â€“ quick setup & wiring guide (â‰¤ 300 words)

All files should be saved in Replit root so I can click â€œRunâ€ and test.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… SUCCESS CRITERIA

After integrating your output:

AI no longer answers with generic â€œMain samajh gayaâ€ lines.

For input â€œKal se pet dard aur ulti ho rahi hai, bukhaar bhi 101 haiâ€ the extracted entities list must include pain (abdomen), vomiting, fever (high).

The subsequent LLM reply must:
â€¢ Restate each symptom in Hinglish,
â€¢ Ask at least one clarifying question (duration, intensity, triggers),
â€¢ Suggest a likely diagnosis set (e.g., gastroenteritis, food poisoning) and relevant tests (CBC, stool test),
â€¢ Prescribe safe medicine examples with dosage.

If the user later says â€œAur aaj se pet me jalan bhi haiâ€, the assistant must merge this into the same context and refine its assessment.